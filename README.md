# ğŸ§¬ Pan-Cancer Nuclei Segmentation (PanNuke)

An **end-to-end deep learning pipeline** for nuclei segmentation and type prediction on the **PanNuke dataset**.  
This project integrates data preprocessing, training with **TransUNet** and evaluation, and prediction.

---

## ğŸš€ Features
- ğŸ”„ **Automated Data Split** (train/test)
- ğŸ§© **Multi-task Learning**: Segmentation + Type prediction
- âš¡ **GPU-accelerated training** (PyTorch)
- ğŸ“Š **Comprehensive Evaluation** (Dice, IoU, F1, Accuracy)
- ğŸ’¾ **Checkpointing**: Avoid redundant retraining
- ğŸ” **Leakage Detection** between train/test sets

---

## âš™ï¸ Environment Setup

```bash
python -m venv .venv
# On Windows:
.venv\Scripts\activate
# On macOS/Linux:
source .venv/bin/activate

pip install -r requirements.txt
```

> **Note:** Please place the folder on Desktop to avoid path issues.

Tested with **Python 3.10+** and **PyTorch 2.1+**. For CUDA, install the matching `torch` build from the official [PyTorch instructions](https://pytorch.org/).

---

## ğŸ–¥ï¸ Hardware Requirements

- **Operating System:** Linux / Windows / macOS
- **CPU:** Recommended 20 cores or more
- **RAM:** Recommended 64GB or more
- **GPU:** NVIDIA CUDA GPU with at least 16GB VRAM
- **Disk Space:** Recommended 100GB free space

### âœ… Test Environment
- Ubuntu 22.04
- Python 3.10
- CUDA 12.1, cuDNN 8.9
- NVIDIA RTX 5070Ti (16GB)

---

## ğŸ“‚ Project Structure

```
pannuke_project/
â”œâ”€ main_pipeline.py
â”œâ”€ segmentor/
â”‚  â”œâ”€ transunet.py
â”‚  â””â”€ train_segmentor.py
â”œâ”€ preprocess/
â”‚  â”œâ”€ data_loader.py
â”‚  â””â”€ shuffle_and_split_pannuke.py
â”œâ”€ evaluate/
â”‚  â”œâ”€ evaluate.py
â”‚  â””â”€ metrics.py
â”œâ”€ data/
â”‚  â”œâ”€ images/            # *_images.npy (raw bundles)
â”‚  â”œâ”€ masks/             # *_masks.npy (raw bundles)
â”‚  â”œâ”€ types/             # *_types.npy (raw bundles)
â”‚  â”œâ”€ train/             # auto-generated split
â”‚  â””â”€ test/              # auto-generated split
â”œâ”€ checkpoints/
â”‚  â”œâ”€ dino/
â”‚  â””â”€ segmentor/
â””â”€ predictions/
```

> **Important:** The pipeline uses relative paths. Keep `TEST_ROOT = PANNUKE_ROOT / 'test'` (avoid hard-coded absolute paths).

---

## ğŸ“Š Data Setup

Place your PanNuke bundles under `data/`:

- `data/images/*_images.npy`
- `data/masks/*_masks.npy`
- `data/types/*_types.npy`

### Split Options

**A. Auto-split (default in `main_pipeline.py`)**  
If `data/train/images.npy` is missing, the pipeline will:
- Find `*_images.npy` (and matching masks/types if present)
- Concatenate
- Create `data/train/` and `data/test/` according to `SPLIT_RATIO` (default = 0.8)

**B. Manual Split Script**
```bash
python preprocess/shuffle_and_split_pannuke.py --data_root data --train_ratio 0.8 --seed 42
```

---

## ğŸ‹ï¸ Training & Prediction

Run the full pipeline (auto-downloads DINO weights if missing):

```bash
python main_pipeline.py
```

Workflow:
1. Ensure pretrained DINO weights (download if needed)
2. Ensure dataset split (auto or existing)
3. Train via `segmentor/train_segmentor.py`
4. Save checkpoints to `checkpoints/segmentor/`
5. Predict results into `predictions/`:
   - `{split}_pred_types.npy`
   - `{split}_pred_seg.npy`
   - `single_masks/` (per-image exports)

### Environment Variables
- `ON_EXIST` = `ask` | `retrain` | `predict` â†’ Behavior when `model_final.pth` exists
- `SEG_BSZ` (default `12`) â†’ Batch size
- `SEG_WORKERS` (default `18`) â†’ DataLoader workers
- `W_ORG` (default `0.2`) â†’ Loss weight for organ branch
- `SPLIT_RATIO` (default `0.8`) â†’ Train/test split ratio
- `SPLIT_SEED` (default `42`) â†’ RNG seed
- `CUDA_VISIBLE_DEVICES` â†’ Specify GPUs

Example:
```bash
ON_EXIST=retrain SEG_BSZ=8 SEG_WORKERS=8 python main_pipeline.py
```

---

## ğŸ“ˆ Results

### Training & Testing Metrics

![Train/Test Metrics](docs/media/metrics.png)

### Segmentation Overlay Example

![Segmentation Overlay](docs/media/seg_overlay.png)

### Key Scores
| Split | Dice  | IoU   | Organ Top-1 |
|-------|-------|-------|-------------|
| Train | 0.9504 | 0.9054 | 0.6878 |
| Test  | 0.9439 | 0.8937 | 0.5349 |

ğŸ“¥ **Inference Download**: [Google Drive Link](https://drive.google.com/file/d/1d-w3jOuPZsPWLxZBIMaNjzvJdb8G2lT_/view?usp=sharing)

---

## ğŸ–¼ï¸ Demo

**Inference build:** [Download here](https://drive.google.com/file/d/1d-w3jOuPZsPWLxZBIMaNjzvJdb8G2lT_/view?usp=sharing)


---

## â— Common Issues
- **Hard-coded paths** â†’ Ensure `TEST_ROOT = PANNUKE_ROOT / 'test'`
- **Missing masks** â†’ Verify `data/test/masks/*.npy` exists & matches `images` stems
- **Mixed shapes/logits** â†’ Evaluation scripts handle `argmax`, but confirm model outputs
- **CUDA errors** â†’ Set `CUDA_VISIBLE_DEVICES=` to force CPU or install CUDA-enabled PyTorch

---

## ğŸ“œ License & Dataset
This project trains on the **PanNuke dataset**. Please comply with the datasetâ€™s license and citation requirements.

---

âœ¨ Maintained with passion for advancing **computational pathology** and **medical imaging AI**.

